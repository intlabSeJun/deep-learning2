#계산 고속화
"""
고속화의 관점에서 데이터의 비트 정밀도를 의식해 구현, 계산이 오래 걸리는 부분만 선택적으로 GPU 실행 가능하다록 함.
넘파이의 부동소수점 수는 기본적으로 64비트 데이터 타입을 사용 ( os/파이썬 버전에 따라서 다름)
"""
import numpy as np
a = np.random.randn(3)
print(a.dtype) #float64
#신경망 학습/추론은 32비트로도 문제없이 수행가능
# -> 메모리 관점에서는 32비트ㅏ 좋다.
# -> 신경망 계산 시 데이터를 전송하는 '버스 대역폭'이 작은게 유리하다.
# -> 속도에서도 더 빠르다

#float32 사용
b = np.random.randn(3).astype(np.float32)
print(b.dtype)
c = np.random.randn(3).astype('f')
print(c.dtype)

# 만약 신경망 추론으로 한정하면 16비트를 사용해도 문제가 되지 않음. 하지만 cpu나 GPU는 32비트로 연산자체를 수행하기 때문에 그다지 혜택은 없다.
# 그러나 학습된 가중치를 저장할 떄에는 16비트가 유효함. 따라서 저장할 경우에는 16비트로 하는게 좋다.

# 딥러닝이 주목받으면서 최근 GPU들은 '저장'과 '연산' 모두에 16비트 반정밀도 부동소수점 수를 지원하도록 진화함. 구글 TPU칩은 8비트 계산도 지원

